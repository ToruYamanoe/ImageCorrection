import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger, MLFlowLogger

from models.blur import BlurModel
from models.model import LitImageCorrection
from datasets import ImageDataModule

from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st

from argparse import Namespace

# å¿…è¦ãªå¼•æ•°ã‚’è¨­å®š
args_dict = {
    "model": "vdsr",
    "loss": "original",
    "lr": 1e-4,
    "sp": 64,
    "sphere": 0.8,
    "cylinder": 0.0,
    "axis": 0,
    "radius": 1.5,
    "img_shape": [3, 500, 500],
    "wide_range": False
}
args = Namespace(**args_dict)

def levenshtein_distance(s1, s2):
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)

    if len(s2) == 0:
        return len(s1)

    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row

    return previous_row[-1]

@st.cache_resource
def load_models():
    """
    Load the image correction model and the blur model.
    """
    checkpoint_path = "./lightning_logs/default/MSE+OCR/checkpoints/epoch=210-step=10128.ckpt"
    try:
        model = LitImageCorrection.load_from_checkpoint(checkpoint_path=checkpoint_path, args=args)
        model.eval()
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

    try:
        blur_model = BlurModel(S=args_dict["sphere"])
        blur_model.eval()
    except Exception as e:
        st.error(f"ã¼ã‹ã—ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

    return model, blur_model

def preprocess_image(uploaded_file):
    """
    Preprocess the uploaded image for the model.
    """
    try:
        image = Image.open(uploaded_file)
        if image.mode != "RGB":
            image = image.convert("RGB")
        return image
    except Exception as e:
        st.error(f"ç”»åƒã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

def postprocess_tensor(tensor):
    """
    Convert a tensor back to a PIL image.
    """
    tensor = tensor.squeeze(0).detach().cpu()
    tensor = torch.clamp(tensor, 0.0, 1.0)
    tensor = tensor.permute(1, 2, 0).numpy() * 255.0
    tensor = tensor.astype(np.uint8)
    return Image.fromarray(tensor)

def main():
    # ãƒšãƒ¼ã‚¸è¨­å®šã¨ã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
    st.set_page_config(
        page_title="å±ˆæŠ˜ç•°å¸¸ç”»åƒè£œæ­£ã‚¢ãƒ—ãƒª",
        page_icon="ğŸ”",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    # ã‚«ã‚¹ã‚¿ãƒ CSSã®é©ç”¨
    st.markdown(
        """
        <style>
        .title {
            font-size: 2.5rem;
            text-align: center;
            color: #4CAF50;
            margin-bottom: 20px;
        }
        .description {
            font-size: 1.2rem;
            text-align: center;
            color: #555555;
            margin-bottom: 40px;
        }
        .image-caption {
            font-size: 1rem;
            text-align: center;
            color: #333333;
            margin-top: 10px;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
    st.markdown('<div class="title">ğŸ” å±ˆæŠ˜ç•°å¸¸ã®ç‚ºã®ç”»åƒè£œæ­£ã‚¢ãƒ—ãƒª</div>', unsafe_allow_html=True)
    st.markdown('<div class="description">ã“ã®æŠ€è¡“ã¯å±ˆæŠ˜ç•°å¸¸ã‚’æŒã¤äººãŒè£¸çœ¼ã§è¦‹ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦ç”»åƒã‚’è£œæ­£ã™ã‚‹æŠ€è¡“ã§ã™ã€‚2023å¹´åº¦ã®å±±ä¹‹ä¸Šæš¢ã®ä¿®è«–ã®æˆæœç‰©ã§ã™ã€‚</div>', unsafe_allow_html=True)

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®ç”»åƒã‚½ãƒ¼ã‚¹é¸æŠ
    img_source = st.sidebar.radio(
        "ç”»åƒã®ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ç”»åƒã‚’æ’®å½±")
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã¾ãŸã¯ã‚«ãƒ¡ãƒ©å…¥åŠ›
    if img_source == "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_file = st.sidebar.file_uploader("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", type=["png", "jpg", "jpeg"])
    else:
        uploaded_file = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±")

    if uploaded_file is not None:
        # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã®é–‹å§‹
        with st.spinner('ç”»åƒã‚’å‡¦ç†ä¸­...'):
            # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
            model, blur_model = load_models()

            # ç”»åƒã®å‰å‡¦ç†
            input_image = preprocess_image(uploaded_file)
            input_image_tensor = torch.from_numpy(np.array(input_image).astype(np.float32) / 255.0).permute(2, 0, 1).unsqueeze(0)

            # ã¼ã‹ã—ãƒ¢ãƒ‡ãƒ«ã®é©ç”¨
            with torch.no_grad():
                blurred_tensor = blur_model(input_image_tensor)
            blurred_image = postprocess_tensor(blurred_tensor)

            # è£œæ­£ãƒ¢ãƒ‡ãƒ«ã®é©ç”¨
            with torch.no_grad():
                corrected_tensor = model(input_image_tensor)
            corrected_image = postprocess_tensor(corrected_tensor)

            # # å†åº¦ã¼ã‹ã—ãƒ¢ãƒ‡ãƒ«ã®é©ç”¨
            # with torch.no_grad():
            #     recorrected_tensor = blur_model(corrected_tensor)
            # recorrected_image = postprocess_tensor(recorrected_tensor)

        # ç”»åƒã®è¡¨ç¤º
        st.markdown("### ç”»åƒã®æ¯”è¼ƒ")
        cols = st.columns(3)
        with cols[0]:
            st.image(input_image,  use_column_width=True)
            st.markdown('<div class="image-caption">å…¥åŠ›ç”»åƒ</div>', unsafe_allow_html=True)
        with cols[1]:
            st.image(blurred_image,  use_column_width=True)
            st.markdown('<div class="image-caption">ã¼ã‹ã—ãŸå…¥åŠ›ç”»åƒ</div>', unsafe_allow_html=True)
        with cols[2]:
            st.image(corrected_image, use_column_width=True)
            st.markdown('<div class="image-caption">AIã§è£œæ­£ã•ã‚ŒãŸç”»åƒ</div>', unsafe_allow_html=True)
        # with cols[2]:
        #     st.image(recorrected_image, use_column_width=True)
        #     st.markdown('<div class="image-caption">AIã§è£œæ­£ã—ãŸç”»åƒã‚’ã¼ã‹ã—ãŸç”»åƒ</div>', unsafe_allow_html=True)

        # èª¬æ˜æ–‡ã‚„è¿½åŠ æƒ…å ±ã®è¡¨ç¤º
        st.markdown("""
        ---
        **è£œæ­£ãƒ—ãƒ­ã‚»ã‚¹ã«ã¤ã„ã¦:**
        - **å…¥åŠ›ç”»åƒ:** å…¥åŠ›ç”»åƒã€‚                    
        - **ã¼ã‹ã—ãŸå…¥åŠ›ç”»åƒ:** å…¥åŠ›ç”»åƒã«å±ˆæŠ˜ç•°å¸¸ã‚’æ¨¡æ“¬ã—ãŸã¼ã‹ã—ã‚’é©ç”¨ã€‚
        - **è£œæ­£ã•ã‚ŒãŸç”»åƒ:** ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã£ã¦è£œæ­£ã•ã‚ŒãŸç”»åƒã€‚
        """)
    else:
        st.info("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
